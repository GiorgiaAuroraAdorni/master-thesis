In recent years, robotics research has dedicated extensive attention to cooperative 
multi-agent problems, in which agents have a common goal that requires them to 
collaborate, and possibly to communicate, to achieve it.
We investigate imitation learning algorithms to address this issue, providing new 
insights and promising solutions. 
These methods learn a controller by observing demonstrations of an expert, such 
as the behaviour of a centralised omniscient controller, which can perceive the 
entire environment, including the state and observations of all agents. 

Performing tasks with complete knowledge of the state of a system is relatively 
easy, but centralised solutions might not be feasible in real scenarios since agents 
do not have direct access to the state but only to their own observations.
%FIXME add input e output * rifrasa
%To overcome this issue, we train end-to-end \glspl{nn}, usually classifiers or 
%regressors, that only exploit local observations and communications, learning 
%decentralised solution via imitation of a centralised control, which indicates the 
%action to be performed.
To overcome this issue, we train end-to-end \glspl{nn}, usually classifiers or 
regressors, that take as input local observations obtained from an omniscient 
centralised controller, in other words the agents' sensor readings, and the 
communications received, producing as output the action to be performed and 
the communication to be transmitted.

In this study, we focus on two different scenarios: distributing the robots in space 
such that they stand at equal distance from each other, and colouring the robots 
in space depending on their position with respect to the others in the group.
Both are examples of cooperative tasks based on the use of a distributed 
controller. While the second cannot be solved without allowing an explicit 
exchange of messages between the agents, in the first one, a communication 
protocol is not necessary, although it may increase performance.

The experiments are run in Enki, a high-performance open-source simulator for 
planar robots, which provides collision detection and limited physics support for 
robots evolving on a flat surface. Moreover, it can simulate groups of robots 
hundreds of times faster than real-time.

%In addition to analysing typical supervised learning approaches, which directly 
%learn a mapping from observations to actions, we concentrate on more 
%challenging situations where the communication is not provided to the network, 
%instead it is a latent variable which has to be inferred.

The results show how applying a communication strategy improves the 
performance of the distributed model, letting it decide which actions to take 
almost as precisely and quickly as the expert controller.