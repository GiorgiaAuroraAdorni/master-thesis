In robotics, performing tasks with complete knowledge of the environment is 
relatively easy but not always feasible. A more challenging situation arises 
when the environment can be observed only partially with the robot's sensors. 
Imitation learning approaches this problem and provides new insights and 
promising solutions to the problem of coordinating multiple agents, where
communication between them becomes essential.

In this master's thesis, we train end-to-end \gls{nn} to perform specific 
tasks for multiple coordinating agents. The experiments are run in Enki 
\cite[see][]{enki}, a high-performance open-source simulator for planar robots, 
which provides collision detection and limited physics support for robots evolving 
on a flat surface. Moreover, it can simulate groups of robots hundreds of times 
faster than real-time.

This study focuses on two different approaches, both based on the use of a 
distributed controller which employs different local controllers for each of the 
agents in order to decide the actions to perform. 
We prove that coordinating the agents to reach a common goal is not easy and 
neither sufficient using a distributed approach alone. Instead, the interactions 
among the agents can be inferred by a model that in addition to the action to 
perform learns the coordination, in the form of communication. 
The models are first trained following the example of an expert controller that 
exploits its complete knowledge of the environment to solve different tasks and 
then tested in the simulator by comparing them to a manual controller.

The results provide some support on how applying a communication 
strategy improves the performance of the distributed model and how the 
exchange of messages between the agents, together with the agents' local 
observations, let the communication controller decides which actions to take 
almost as precisely and quickly as the expert does.
