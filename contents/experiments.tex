\chapter{Experiments}
\label{chap:experiments}

%\section{Overview}
%\label{sec:overview}

In this work, we investigate collaborative multi-agent problems in a \gls{1d} 
simulated environment.

The environment is represented by a Cartesian plane, a system of coordinates
defined by two perpendicular axes, $x$ and $y$. 

In this scenario, $N$ robots, all oriented in the same direction, are initially 
randomly placed along the x-axis, avoiding collisions and in such a way the 
average gap among the agents is included in the proximity sensors' ranges. 
All the robots act in collaboration to achieve a common goal, however the first 
and last in the row behave like walls. %% FIXME

The agent is a point in the plane, formally described by a homogeneous vector 
with respect to the world coordinate frame $W$, obtained multiplying the 
homogeneous vector of the point, \gls{wrt}  the robot coordinate frame 
$A$, by a homogeneous transformation. 

The relative pose $A$ of each agent is identified by a $3 \times 3$ matrix 
$\mathbf{T}$, \gls{wrt} the world reference frame $W$. 

\begin{Equation}[!htb]
	\centering
	\begin{equation}
	\label{eq:homogeneous transformation matrix}
	{^W\!\xi_A} = {^W\!\mathbf{T}_A} 
	=
	\begin{pmatrix}
	^W\!\mathbf{R}_A & ^W\!\mathbf{t}_A\\
	0, 0 & 1
	\end{pmatrix}
	=
	\begin{pmatrix}
	\cos \theta & - \sin \theta & t_x\\
	\sin \theta & \cos \theta & t_y\\
	0 & 0 & 1
	\end{pmatrix}
	\end{equation}
	\caption[Homogeneous Transformation Matrix]{The homogeneous 
	transformation matrix, 	$^W\!\mathbf{T}_A$, includes $^W\!\mathbf{R}_A$, a 
	$2 \times 2$ rotation matrix and $^W\!\mathbf{t}_A$, a $2 \times 1$ 
	translation vector.}
	\label{eq:hommatrix}
\end{Equation}

However, since we are in a \gls{1d} environment, the $y$ coordinate is equal 
to $0$ and also the orientation angle $\theta$ must be zero as all the agents are 
oriented as the world frame. 

Moreover, we can consider the agents as holonomic, since their movements are 
limited in only one dimension. This premise simplifies our system, in which 
consequently we have to keep into account only geometric constraints and not
kinematic.

\section{Controllers}
\label{sec:controllers}

In a \gls{mas}, each agent can perceive the environment through sensors 
acquiring a total or partial knowledge of it. The observations extracted can be 
used by a controller, together with the current state of the agent, to determine 
actions, draw inferences and finally solve tasks. 

In an imitation learning setting, there are two controllers involved: an expert 
controller, which performs the desired task with perfect knowledge of the 
environment, and a learned controller, which is trained to imitate the behaviour 
of the omniscient controller.

For each of the task that we are going to face, we introduce three controllers: the 
expert controller, that exploits its complete knowledge of the state of the system 
to decide the best action to perform, the manual controller, that has only a partial 
knowledge of it, and a controller learned by imitating the expert one.

These controllers will be described in detail later in the sections dedicated to each 
task.

\section{Datasets generation}
\input{contents/task1}
\input{contents/task2}
